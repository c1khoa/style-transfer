{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def style_sampling(base_path, dest_path, n_samples=100, split=(0.8, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Lấy mẫu ảnh từ mỗi style và chia đều train/valid/test.\n",
    "    Đặt tên file dạng style_001.jpg, style_002.jpg...\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): thư mục chứa các folder style\n",
    "        dest_path (str): thư mục lưu kết quả\n",
    "        n_samples (int): số ảnh lấy mẫu cho mỗi style\n",
    "        split (tuple): tỉ lệ chia train/valid/test\n",
    "    \"\"\"\n",
    "    random.seed(2025)\n",
    "    \n",
    "    subsets = [\"train\", \"valid\", \"test\"]\n",
    "    for subset in subsets:\n",
    "        os.makedirs(os.path.join(dest_path, subset), exist_ok=True)\n",
    "    \n",
    "    styles = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    total_copied = 0\n",
    "\n",
    "    for style in tqdm(styles, desc=\"Sampling styles\"):\n",
    "        style_path = os.path.join(base_path, style)\n",
    "        # Lọc file ảnh\n",
    "        image_files = [f for f in os.listdir(style_path) \n",
    "                       if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "        if not image_files:\n",
    "            continue\n",
    "\n",
    "        # Lấy mẫu ngẫu nhiên\n",
    "        sample_imgs = random.sample(image_files, min(len(image_files), n_samples))\n",
    "        n = len(sample_imgs)\n",
    "\n",
    "        # Số lượng cho train/valid/test (làm tròn xuống)\n",
    "        n_train = int(n * split[0])\n",
    "        n_valid = int(n * split[1])\n",
    "        n_test = n - n_train - n_valid\n",
    "\n",
    "        # Chia ảnh\n",
    "        split_dict = {\n",
    "            \"train\": sample_imgs[:n_train],\n",
    "            \"valid\": sample_imgs[n_train:n_train+n_valid],\n",
    "            \"test\": sample_imgs[n_train+n_valid:]\n",
    "        }\n",
    "\n",
    "        # Copy ảnh sang folder tương ứng với tên style_index.jpg\n",
    "        for subset, imgs in split_dict.items():\n",
    "            dest_folder = os.path.join(dest_path, subset)\n",
    "            for idx, img_name in enumerate(imgs, start=1):\n",
    "                src = os.path.join(style_path, img_name)\n",
    "                dst_name = f\"{style}_{idx:03d}.jpg\"  # style_001.jpg, style_002.jpg...\n",
    "                dst = os.path.join(dest_folder, dst_name)\n",
    "                shutil.copy(src, dst)\n",
    "                total_copied += 1\n",
    "\n",
    "    print(f\"Đã sao chép {total_copied} ảnh từ {len(styles)} style vào {dest_path}/train, valid, test\")\n",
    "\n",
    "\n",
    "# ------------------- Transform -------------------\n",
    "class TransformImageNet:\n",
    "    def __init__(self, target_long=512, min_short=256, crop_size=None, gray_ratio=0.0):\n",
    "        \"\"\"\n",
    "        target_long: cạnh lớn của ảnh sau resize\n",
    "        min_short: nếu cạnh nhỏ < min_short, sẽ padding\n",
    "        crop_size: nếu muốn crop, None = không crop\n",
    "        gray_ratio: xác suất chuyển ảnh sang grayscale\n",
    "        \"\"\"\n",
    "        self.target_long = target_long\n",
    "        self.min_short = min_short\n",
    "        self.crop_size = crop_size\n",
    "        self.gray_ratio = gray_ratio\n",
    "        self.to_tensor = T.ToTensor()\n",
    "        self.normalize = T.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                     std=[0.229,0.224,0.225])\n",
    "\n",
    "    def resize_and_pad(self, img):\n",
    "        w, h = img.size\n",
    "        # scale tỉ lệ theo cạnh lớn\n",
    "        if w > h:\n",
    "            new_w = self.target_long\n",
    "            new_h = int(h * self.target_long / w)\n",
    "        else:\n",
    "            new_h = self.target_long\n",
    "            new_w = int(w * self.target_long / h)\n",
    "        img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
    "\n",
    "        # padding nếu cạnh nhỏ < min_short\n",
    "        pad_w = max(0, self.min_short - new_w)\n",
    "        pad_h = max(0, self.min_short - new_h)\n",
    "        if pad_w > 0 or pad_h > 0:\n",
    "            img = F.pad(img, (0,0,pad_w,pad_h), fill=0)\n",
    "        return img\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Grayscale augmentation\n",
    "        if random.random() < self.gray_ratio:\n",
    "            img = img.convert(\"L\").convert(\"RGB\")\n",
    "\n",
    "        img = self.resize_and_pad(img)\n",
    "\n",
    "        # RandomCrop nếu muốn\n",
    "        if self.crop_size:\n",
    "            img = T.RandomCrop(self.crop_size)(img)\n",
    "\n",
    "        img = self.to_tensor(img)\n",
    "        img = self.normalize(img)\n",
    "        return img\n",
    "\n",
    "# ------------------- Dataset -------------------\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, content_folder, style_folder, subset,\n",
    "                 transform=None, gray_ratio=0.2,\n",
    "                 valid_ext=('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "        self.content_folder = os.path.join(content_folder, subset)\n",
    "        self.style_folder = os.path.join(style_folder, subset)\n",
    "\n",
    "        self.content_files = []\n",
    "        self.style_files = []\n",
    "\n",
    "        for ext in valid_ext:\n",
    "            self.content_files.extend(glob.glob(os.path.join(self.content_folder, f\"*{ext}\")))\n",
    "            self.style_files.extend(glob.glob(os.path.join(self.style_folder, f\"*{ext}\")))\n",
    "\n",
    "        self.content_files = sorted(self.content_files)\n",
    "        self.style_files = sorted(self.style_files)\n",
    "\n",
    "        if len(self.content_files) == 0:\n",
    "            raise RuntimeError(f\"No content images found in {self.content_folder}\")\n",
    "        if len(self.style_files) == 0:\n",
    "            raise RuntimeError(f\"No style images found in {self.style_folder}\")\n",
    "\n",
    "        self.transform = transform\n",
    "        self.gray_ratio = gray_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.content_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Content image\n",
    "        content_path = self.content_files[idx]\n",
    "        content_img = Image.open(content_path).convert(\"RGB\")\n",
    "        \n",
    "        # Style image (random)\n",
    "        style_path = random.choice(self.style_files)\n",
    "        style_img = Image.open(style_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            content_img = self.transform(content_img)\n",
    "            style_img = self.transform(style_img)\n",
    "\n",
    "        return content_img, style_img\n",
    "\n",
    "# ------------------- DataLoader factory -------------------\n",
    "def get_dataloaders(content_folder, style_folder,\n",
    "                    batch_size=8, num_workers=4, gray_ratio=0.2,\n",
    "                    target_long=512, min_short=256, crop_size=256):\n",
    "    \"\"\"\n",
    "    Tạo DataLoader cho train/valid/test.\n",
    "    Giả sử content_folder và style_folder đã có subfolder 'train', 'valid', 'test'.\n",
    "    Có thể bật tqdm để quan sát tiến trình load dữ liệu.\n",
    "    \"\"\"\n",
    "    transform = TransformImageNet(\n",
    "        target_long=target_long,\n",
    "        min_short=min_short,\n",
    "        crop_size=crop_size,\n",
    "        gray_ratio=gray_ratio\n",
    "    )\n",
    "\n",
    "    loaders = {}\n",
    "    for subset in [\"train\", \"valid\", \"test\"]:\n",
    "        dataset = CustomImageDataset(\n",
    "            content_folder,\n",
    "            style_folder,\n",
    "            subset=subset,\n",
    "            transform=transform,\n",
    "            gray_ratio=gray_ratio\n",
    "        )\n",
    "        shuffle = (subset == \"train\")\n",
    "\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        loaders[subset] = loader\n",
    "\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f672d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling styles:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling styles: 100%|██████████| 27/27 [00:06<00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã sao chép 2698 ảnh từ 27 style vào ../data/wikiart_sampled/train, valid, test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../data/wikiart\"\n",
    "dest_path = \"../data/wikiart_sampled\"\n",
    "n_samples = 100\n",
    "style_sampling(base_path, dest_path, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da8498fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content.shape: torch.Size([8, 3, 256, 256])\n",
      "style.shape: torch.Size([8, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "loader = get_dataloaders(content_folder=\"../data/coco2017\",\n",
    "                         style_folder=\"../data/wikiart_sampled\", num_workers=0)\n",
    "content, style = next(iter(loader['train']))\n",
    "print(\"content.shape:\", content.shape)\n",
    "print(\"style.shape:\", style.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
