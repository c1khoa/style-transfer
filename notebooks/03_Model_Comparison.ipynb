{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Comparison: AdaIN vs SANet\n",
        "\n",
        "So sánh performance và output quality của 2 models:\n",
        "- AdaIN (Adaptive Instance Normalization)\n",
        "- SANet (Style Attentional Network)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paths to Checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ADAIN_CHECKPOINT = \"../checkpoints/adain/adain_best.pth\"\n",
        "SANET_DECODER = \"../checkpoints/sanet/decoder_best.pth\"\n",
        "SANET_TRANSFORM = \"../checkpoints/sanet/transformer_best.pth\"\n",
        "VGG_PATH_ADAIN = \"../models/vgg16-encoder.pth\"\n",
        "VGG_PATH_SANET = \"../models/vgg_normalised.pth\"\n",
        "\n",
        "print(\"Checkpoint paths configured:\")\n",
        "print(f\"  AdaIN: {os.path.exists(ADAIN_CHECKPOINT)}\")\n",
        "print(f\"  SANet Decoder: {os.path.exists(SANET_DECODER)}\")\n",
        "print(f\"  SANet Transform: {os.path.exists(SANET_TRANSFORM)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Comparison\n",
        "\n",
        "**Key Differences:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"MODEL COMPARISON SUMMARY: AdaIN vs SANet\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. ARCHITECTURE:\")\n",
        "print(\"   AdaIN:\")\n",
        "print(\"     - VGG encoder (pretrained)\")\n",
        "print(\"     - AdaIN layer (adaptive instance normalization)\")\n",
        "print(\"     - Custom decoder với residual blocks\")\n",
        "print(\"     - Đơn giản và Nhanh\")\n",
        "print(\"\\n   SANet:\")\n",
        "print(\"     - VGG encoder (pretrained)\")\n",
        "print(\"     - SANet layers (style attention networks)\")\n",
        "print(\"     - Multi-level feature fusion (relu4_1 + relu5_1)\")\n",
        "print(\"     - Phức tạp hơn AdaIN\")\n",
        "\n",
        "print(\"\\n2. TRAINING RESULTS:\")\n",
        "print(\"   AdaIN:\")\n",
        "print(\"     - Training: 30 epochs\")\n",
        "print(\"     - Best Val Loss: ~3.34\")\n",
        "print(\"     - Converged quickly\")\n",
        "print(\"     - Checkpoint: ../checkpoints/adain/adain_best.pth\")\n",
        "print(\"\\n   SANet:\")\n",
        "print(\"     - Training: 145k iterations - epoch 10\")\n",
        "print(\"     - Best Val Loss: ~14.89 (iteration 145k)\")\n",
        "print(\"     - Thời gian train dài hơn\")\n",
        "print(\"     - Checkpoint: ../checkpoints/sanet/sanet_*_best.pth\")\n",
        "\n",
        "print(\"\\n3. OUTPUT QUALITY (Based on visual inspection):\")\n",
        "print(\"   AdaIN:\")\n",
        "print(\"     + Sharpness: 9/10 - Rõ nét, edges clear\")\n",
        "print(\"     + Inference nhanh\")\n",
        "print(\"     + Content preservation tốt\")\n",
        "print(\"     - Style Transfer: 7/10 - Style patterns yếu hơn\")\n",
        "print(\"     - Ít artistic, còn giữ nhiều content structure\")\n",
        "print(\"\\n   SANet:\")\n",
        "print(\"     + Style Transfer: 9/10 - Style patterns mạnh, rõ ràng\")\n",
        "print(\"     + Color blending tự nhiên\")\n",
        "print(\"     + Attention mechanism apply style tốt hơn\")\n",
        "print(\"     + Artistic outputs đẹp hơn\")\n",
        "print(\"     - Sharpness: 6/10 - Bị blur, edges không sharp\")\n",
        "print(\"     - Đã peak ở 145k, không cải thiện được thêm\")\n",
        "\n",
        "print(\"\\n4. INFERENCE SPEED (estimated):\")\n",
        "print(\"   AdaIN: ~0.05-0.1s/image\")\n",
        "print(\"   SANet: ~0.1-0.2s/image\")\n",
        "print(\"   (Tùy vào máy và style image)\")\n",
        "\n",
        "print(\"\\n5. TRADE-OFF & RECOMMENDATION:\")\n",
        "print(\"   SANet: Style Quality (9/10) vs Sharpness (6/10)\")\n",
        "print(\"   AdaIN: Sharpness (9/10) vs Style Quality (7/10)\")\n",
        "print(\"\")\n",
        "print(\"   Use case:\")\n",
        "print(\"     -> Artistic, style-heavy outputs: SANet\")\n",
        "print(\"     -> Sharp, production outputs: AdaIN\")\n",
        "print(\"\")\n",
        "print(\"   Cho đồ án này:\")\n",
        "print(\"     -> Dùng CẢ 2 models để demo\")\n",
        "print(\"     -> SANet: Show strong style transfer capability\")\n",
        "print(\"     -> AdaIN: Show sharpness + inference speed\")\n",
        "print(\"     -> Nhấn mạnh trade-offs trong report\")\n",
        "print(\"\")\n",
        "print(\"   Note:\")\n",
        "print(\"     -> SANet đã peak ở 145k iterations\")\n",
        "print(\"     -> Training thêm chỉ làm tăng loss (overfitting)\")\n",
        "print(\"     -> Trade-off hiện tại là cuối cùng của model này\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CONCLUSION: Both models có strengths khác nhau - dùng cả 2!\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visual Comparison\n",
        "\n",
        "Hiển thị output từ checkpoint có sẵn:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sanet_outputs = glob.glob(\"../results/sanet/*_original.jpg\")\n",
        "\n",
        "if len(sanet_outputs) > 0:\n",
        "    print(f\"Found {len(sanet_outputs)} SANet output images\")\n",
        "    \n",
        "    fig, axes = plt.subplots(len(sanet_outputs), 1, figsize=(12, 4*len(sanet_outputs)))\n",
        "    if len(sanet_outputs) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, img_path in enumerate(sanet_outputs):\n",
        "        img = Image.open(img_path)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f'SANet Output: {os.path.basename(img_path)}', fontsize=12)\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No SANet output images found in ../.checkpoint/output/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Metrics Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "adain_epochs = [1, 5, 10, 15, 20, 25, 30]\n",
        "adain_losses = [8.2, 5.1, 4.3, 3.9, 3.6, 3.4, 3.34]\n",
        "\n",
        "axes[0].plot(adain_epochs, adain_losses, marker='o', linewidth=2, markersize=8)\n",
        "axes[0].set_title('AdaIN Training Loss', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Validation Loss', fontsize=12)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].axhline(y=3.34, color='r', linestyle='--', label='Best: 3.34')\n",
        "axes[0].legend()\n",
        "\n",
        "sanet_iters = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145]\n",
        "sanet_losses = [25.85, 22.28, 21.14, 19.73, 18.52, 18.48, 18.37, 17.68, 17.08, \n",
        "                17.35, 17.35, 17.35, 17.35, 17.35, 15.68, 15.90, 16.44, 15.97, 15.75,\n",
        "                15.60, 15.45, 15.30, 15.15, 15.00, 14.95, 14.92, 14.90, 14.89, 14.89]\n",
        "\n",
        "axes[1].plot(sanet_iters, sanet_losses, marker='s', linewidth=2, markersize=6)\n",
        "axes[1].set_title('SANet Training Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Iteration (x1000)', fontsize=12)\n",
        "axes[1].set_ylabel('Validation Loss', fontsize=12)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].axhline(y=14.89, color='r', linestyle='--', label='Best: 14.89 (145k)')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/training_comparison.jpg', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"KEY OBSERVATIONS:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n1. AdaIN:\")\n",
        "print(\"   - Started at ~8.2, end at 3.34\")\n",
        "print(\"   - Improvement: 58.5%\")\n",
        "print(\"   - Converged in 30 epochs\")\n",
        "print(\"\\n2. SANet:\")\n",
        "print(\"   - Started at ~25.85, end at 14.89\")\n",
        "print(\"   - Improvement: 42.4%\")\n",
        "print(\"\\n3. Loss Scale:\")\n",
        "print(\"   - SANet loss is 4.5x higher than AdaIN (14.89 vs 3.34)\")\n",
        "print(\"   - AdaIN converges faster and to lower loss\")\n",
        "print(\"\\nSaved plot to: ../results/training_comparison.jpg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kết Luận\n",
        "\n",
        "**Trade-off: Style Strength vs Sharpness**\n",
        "\n",
        "### SANet (10 epochs):\n",
        "**Style Transfer Quality: 9/10**\n",
        "- Style patterns rõ ràng, mạnh mẽ hơn AdaIN\n",
        "- Color blending tự nhiên\n",
        "- Attention mechanism apply style tốt hơn\n",
        "- Artistic outputs đẹp hơn\n",
        "\n",
        "**Nhưng: Sharpness: 6/10**\n",
        "- Details không sharp\n",
        "- Edges bị blur\n",
        "- Đã train tối đa, sau 145k chỉ overfitting\n",
        "\n",
        "### AdaIN (30 epochs):\n",
        "**Sharpness: 9/10**\n",
        "- Details preservation tốt\n",
        "- Edges rõ ràng\n",
        "- Training nhanh (30 epochs)\n",
        "- Inference nhanh hơn\n",
        "\n",
        "**Nhưng: Style Transfer Quality: 7/10**\n",
        "- Style patterns yếu hơn SANet\n",
        "- Còn giữ nhiều content structure\n",
        "- Ít artistic hơn\n",
        "\n",
        "---\n",
        "\n",
        "### Recommendation:\n",
        "\n",
        "**Tùy theo use case:**\n",
        "\n",
        "1. **Ưu tiên Style Quality** → **SANet**\n",
        "   - Artistic outputs, style-heavy\n",
        "   - Demo style transfer capability\n",
        "   \n",
        "2. **Ưu tiên Sharpness** → **AdaIN**  \n",
        "   - Production, real-time\n",
        "   - Content preservation\n",
        "\n",
        "**Cho đồ án này:**\n",
        "- Dùng **CẢ 2 models** để demo\n",
        "- SANet: Show strong style transfer\n",
        "- AdaIN: Show sharpness + speed\n",
        "- Nhấn mạnh trade-offs trong report\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
